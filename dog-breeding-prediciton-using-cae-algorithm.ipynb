{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2387160,"sourceType":"datasetVersion","datasetId":453611}],"dockerImageVersionId":31259,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Imports & Environment Setup","metadata":{}},{"cell_type":"code","source":"import os, random, math, numpy as np, pandas as pd\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms\n\nfrom sklearn.metrics import classification_report, confusion_matrix","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-30T12:12:02.678526Z","iopub.execute_input":"2026-01-30T12:12:02.678963Z","iopub.status.idle":"2026-01-30T12:12:15.554248Z","shell.execute_reply.started":"2026-01-30T12:12:02.678921Z","shell.execute_reply":"2026-01-30T12:12:15.553353Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"# Set Random Seeds","metadata":{}},{"cell_type":"code","source":"def seed_all(seed=42):\n    random.seed(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n\nseed_all(42)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-30T12:12:15.555754Z","iopub.execute_input":"2026-01-30T12:12:15.556338Z","iopub.status.idle":"2026-01-30T12:12:15.578243Z","shell.execute_reply.started":"2026-01-30T12:12:15.556306Z","shell.execute_reply":"2026-01-30T12:12:15.577103Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"device(type='cpu')"},"metadata":{}}],"execution_count":3},{"cell_type":"markdown","source":"# Loading Dataset - Dataset Paths (Train / Valid / Test)","metadata":{}},{"cell_type":"code","source":"DATA_ROOT = \"/kaggle/input/70-dog-breedsimage-data-set\"\n\ntrain_dir = os.path.join(DATA_ROOT, \"train\")\nval_dir   = os.path.join(DATA_ROOT, \"valid\")\ntest_dir  = os.path.join(DATA_ROOT, \"test\")\n\nprint(\"Train exists:\", os.path.isdir(train_dir))\nprint(\"Valid exists:\", os.path.isdir(val_dir))\nprint(\"Test exists :\", os.path.isdir(test_dir))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Number of Classes","metadata":{}},{"cell_type":"code","source":"def count_images(root):\n    classes = sorted([d for d in os.listdir(root) if os.path.isdir(os.path.join(root, d))])\n    counts = []\n    for c in classes:\n        cpath = os.path.join(root, c)\n        n = len([f for f in os.listdir(cpath) if f.lower().endswith((\".jpg\",\".jpeg\",\".png\"))])\n        counts.append((c, n))\n    df = pd.DataFrame(counts, columns=[\"class\", \"count\"]).sort_values(\"count\", ascending=False)\n    return df, classes\n\ntrain_df, classes = count_images(train_dir)\nval_df, _ = count_images(val_dir)\ntest_df, _ = count_images(test_dir)\n\nprint(\"Num classes:\", len(classes))\nprint(\"Train images:\", train_df[\"count\"].sum())\nprint(\"Val images  :\", val_df[\"count\"].sum())\nprint(\"Test images :\", test_df[\"count\"].sum())\n\ntrain_df.head()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Class Distribution: Count Images per Breed","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12,4))\nplt.hist(train_df[\"count\"], bins=20)\nplt.title(\"Train: Distribution of images per class\")\nplt.xlabel(\"Images per class\")\nplt.ylabel(\"Number of classes\")\nplt.show()\n\ntrain_df.describe()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Visualize Random Training Samples","metadata":{}},{"cell_type":"code","source":"def show_samples(root, classes, n=12):\n    plt.figure(figsize=(12,8))\n    for i in range(n):\n        c = random.choice(classes)\n        cdir = os.path.join(root, c)\n        img_name = random.choice(os.listdir(cdir))\n        img_path = os.path.join(cdir, img_name)\n        img = Image.open(img_path).convert(\"RGB\")\n        plt.subplot(3,4,i+1)\n        plt.imshow(img)\n        plt.title(c, fontsize=9)\n        plt.axis(\"off\")\n    plt.tight_layout()\n    plt.show()\n\nshow_samples(train_dir, classes, n=12)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Check Image Size Variations","metadata":{}},{"cell_type":"code","source":"from collections import Counter\n\ndef sample_sizes(root, classes, k=300):\n    sizes = []\n    for _ in range(k):\n        c = random.choice(classes)\n        cdir = os.path.join(root, c)\n        img_name = random.choice(os.listdir(cdir))\n        img_path = os.path.join(cdir, img_name)\n        img = Image.open(img_path).convert(\"RGB\")\n        sizes.append(img.size)\n    return Counter(sizes).most_common(10)\n\nsample_sizes(train_dir, classes, k=300)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Compute Dataset Mean & Std for Normalization","metadata":{}},{"cell_type":"code","source":"def compute_mean_std(dataset, num_batches=50, batch_size=64):\n    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=2, pin_memory=True)\n    mean = 0.\n    var  = 0.\n    n = 0\n    for i, (x, _) in enumerate(loader):\n        if i >= num_batches: break\n        x = x.to(device)\n        b = x.size(0)\n        x = x.view(b, x.size(1), -1)\n        mean += x.mean(dim=2).sum(dim=0)\n        var  += x.var(dim=2, unbiased=False).sum(dim=0)\n        n += b\n    mean /= n\n    var  /= n\n    std = torch.sqrt(var)\n    return mean.detach().cpu().numpy(), std.detach().cpu().numpy()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"stats_tf = transforms.Compose([transforms.ToTensor()])\ntmp_ds = datasets.ImageFolder(train_dir, transform=stats_tf)\nmean, std = compute_mean_std(tmp_ds)\nmean, std","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Data Augmentation & Preprocessing Pipelines","metadata":{}},{"cell_type":"code","source":"IMG_SIZE = 256\nBATCH_SIZE = 64\n\ntrain_tf = transforms.Compose([\n    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.7, 1.0)),\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.RandomRotation(10),\n    transforms.RandomAffine(0, translate=(0.05, 0.05)),\n    transforms.ColorJitter(0.2,0.2,0.2,0.1),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=mean, std=std),\n    transforms.RandomErasing(p=0.25, scale=(0.02, 0.12), ratio=(0.3, 3.3)),\n])\n\neval_tf = transforms.Compose([\n    transforms.Resize(IMG_SIZE),\n    transforms.CenterCrop(IMG_SIZE),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=mean, std=std),\n])\n\nfrom torchvision.datasets import ImageFolder\nimport re\n\ndef canon(s: str) -> str:\n    return re.sub(r\"\\s+\", \" \", s.strip()).lower()\n\nclass ImageFolderWithCanonicalMap(ImageFolder):\n    def __init__(self, root, train_class_to_idx, transform=None):\n        super().__init__(root=root, transform=transform)\n        train_c2i = {canon(k): v for k, v in train_class_to_idx.items()}\n        fixed_samples = []\n        missing = set()\n        for path, local_target in self.samples:\n            class_name = self.classes[local_target]\n            key = canon(class_name)\n            if key not in train_c2i:\n                missing.add(class_name)\n                continue\n            fixed_samples.append((path, train_c2i[key]))\n        if missing:\n            print(\"WARNING: unmatched classes:\", list(sorted(missing))[:10], \"...\")\n        self.samples = fixed_samples\n        self.targets = [t for _, t in self.samples]\n\ntrain_ds = ImageFolder(train_dir, transform=train_tf)\nval_ds   = ImageFolderWithCanonicalMap(val_dir,  train_ds.class_to_idx, transform=eval_tf)\ntest_ds  = ImageFolderWithCanonicalMap(test_dir, train_ds.class_to_idx, transform=eval_tf)\n\nnum_classes = len(train_ds.classes)\nprint(\"Classes:\", num_classes)\nprint(\"Val samples:\", len(val_ds))\nprint(\"Test samples:\", len(test_ds))\n\ntrain_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,  num_workers=2, pin_memory=True)\nval_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\ntest_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}